{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download_and_extract(dest_directory, url):\n",
    "  \"\"\"\n",
    "    Download the dataset and extract the data\n",
    "  \"\"\"\n",
    "    \n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  file_name = 'cifar-10-binary.tar.gz'\n",
    "  file_path = os.path.join(dest_directory, file_name)\n",
    "  # if have not downloaded yet\n",
    "  if not os.path.exists(file_path):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r%.1f%%' % \n",
    "            (float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()  # flush the buffer\n",
    "\n",
    "    print('>> Downloading %s ...' % file_name)\n",
    "    file_path, _ = urllib.request.urlretrieve(url, file_path, _progress)\n",
    "    file_size = os.stat(file_path).st_size\n",
    "    print('\\r>> Total %d bytes' % file_size)\n",
    "  extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "  if not os.path.exists(extracted_dir_path):\n",
    "    # Open for reading with gzip compression, then extract all\n",
    "    tarfile.open(file_path, 'r:gz').extractall(dest_directory)\n",
    "  print('>> Done')\n",
    "\n",
    "# download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "DEST_DIRECTORY = './dataset/cifar10'\n",
    "DATA_DIRECTORY = DEST_DIRECTORY + '/cifar-10-batches-bin'\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "IMAGE_SIZE_CROPPED = 24\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10 \n",
    "LABEL_BYTES = 1\n",
    "IMAGE_BYTES = 32 * 32 * 3\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# The record is the image plus a one-byte label\n",
    "_RECORD_BYTES = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_DEPTH + 1\n",
    "# download it\n",
    "maybe_download_and_extract(DEST_DIRECTORY, DATA_URL)\n",
    "training_files = [os.path.join(DATA_DIRECTORY, 'data_batch_%d.bin' % i) for i in range(1,6)]\n",
    "testing_files = [os.path.join(DATA_DIRECTORY, 'test_batch.bin')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) + (6)\n",
    "def read_cifar10(filename_queue):\n",
    "    \"\"\" Reads and parses examples from CIFAR10 data files.\n",
    "    -----\n",
    "    Args:\n",
    "        filename_queue: \n",
    "            A queue of strings with the filenames to read from.\n",
    "    Returns:\n",
    "        An object representing a single example, with the following fields:\n",
    "        height: \n",
    "            number of rows in the result (32)\n",
    "        width: \n",
    "            number of columns in the result (32)\n",
    "        depth: \n",
    "            number of color channels in the result (3)\n",
    "        key: \n",
    "            a scalar string Tensor describing the filename & record number for this example.\n",
    "        label: \n",
    "            an int32 Tensor with the label in the range 0..9.\n",
    "        image: \n",
    "            a [height, width, depth] uint8 Tensor with the image data\n",
    "    \"\"\"\n",
    "\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "\n",
    "    result = CIFAR10Record()\n",
    "    # CIFAR10 consists of 60000 32x32 'color' images in 10 classes\n",
    "    label_bytes = 1  # 10 class\n",
    "    result.height = IMAGE_HEIGHT\n",
    "    result.width = IMAGE_WIDTH\n",
    "    result.depth = IMAGE_DEPTH\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    # bytes of a record: label(1 byte) followed by pixels(3072 bytes)\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    # (5) reader for cifar10 file format\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    # read a record\n",
    "    result.key, record_string = reader.read(filename_queue)\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    # (6) decoder\n",
    "    record_uint8 = tf.decode_raw(record_string, tf.uint8)\n",
    "    # get the label and cast it to int32\n",
    "    result.label = tf.cast(\n",
    "      tf.strided_slice(record_uint8, [0], [label_bytes]), tf.int32)\n",
    "    # [depth, height, width], uint8\n",
    "    depth_major = tf.reshape(\n",
    "      tf.strided_slice(record_uint8, [label_bytes],\n",
    "                       [label_bytes + image_bytes]),\n",
    "      [result.depth, result.height, result.width])\n",
    "    # change to [height, width, depth], uint8\n",
    "    result.image = tf.transpose(depth_major, [1, 2, 0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(object):\n",
    "    def __init__(self, model_hps):\n",
    "        self.image_size = model_hps.image_size\n",
    "        self.batch_size = model_hps.batch_size\n",
    "        self.num_classes = model_hps.num_classes\n",
    "        self.num_training_example = model_hps.num_training_example\n",
    "        self.num_epoch_per_decay = model_hps.num_epoch_per_decay\n",
    "        self.init_lr = model_hps.init_lr  # initial learn rate\n",
    "        self.moving_average_decay = model_hps.moving_average_decay\n",
    "        self.ckpt_dir = model_hps.ckpt_dir\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # op for training\n",
    "        self.global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "\n",
    "        with tf.variable_scope('model'):\n",
    "            self.images = tf.placeholder(tf.float32,[self.batch_size, self.image_size, self.image_size, 3]) \n",
    "            self.labels = tf.placeholder(tf.int32)\n",
    "\n",
    "            self.logits = self.inference(self.images)\n",
    "            self.top_k_op = tf.nn.in_top_k(self.logits, self.labels, 1) \n",
    "            self.total_loss = self.loss(self.logits, self.labels)\n",
    "            self.train_op = self.train(self.total_loss, self.global_step)\n",
    "\n",
    "    def _variable_on_cpu(self, name, shape, initializer):\n",
    "        with tf.device('/cpu:0'):\n",
    "            var = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "\n",
    "        return var\n",
    "\n",
    "    def _variable_with_weight_decay(self, name, shape, stddev, wd=0.0):\n",
    "        \"\"\" Helper to create an initialized Variable with weight decay.\n",
    "            Note that the Variable is initialized with a truncated normal \n",
    "            distribution. A weight decay is added only if one is specified.\n",
    "            -----\n",
    "            Args:\n",
    "                name: \n",
    "                    name of the variable\n",
    "                shape: \n",
    "                    a list of ints\n",
    "                stddev: \n",
    "                    standard deviation of a truncated Gaussian\n",
    "                wd: \n",
    "                    add L2Loss weight decay multiplied by this float. If None, weight\n",
    "                    decay is not added for this Variable.\n",
    "            Returns:\n",
    "                Variable Tensor\n",
    "        \"\"\"\n",
    "        initializer = tf.truncated_normal_initializer(\n",
    "            stddev=stddev, dtype=tf.float32)\n",
    "        var = self._variable_on_cpu(name, shape, initializer)\n",
    "        # deal with weight decay\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "        return var\n",
    "\n",
    "    def _conv_block(self, inp, scope, kernel_width, kernel_height, inp_channel, out_channel, strides = [1, 1, 1, 1], padding='SAME'):\n",
    "        with tf.variable_scope(scope) as scope:\n",
    "            kernel = self._variable_with_weight_decay('weights', [kernel_width, kernel_width, inp_channel, out_channel], 5e-2)\n",
    "            biases = self._variable_on_cpu('bias', [out_channel], tf.constant_initializer(0.0))\n",
    "\n",
    "            conv = tf.nn.conv2d(inp, kernel, strides=strides, padding=padding)\n",
    "            pre_activation = tf.nn.bias_add(conv, biases)\n",
    "            return tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    def _fully_connected_layer(self, inp, scope, in_dim, out_dim, relu = True):\n",
    "        with tf.variable_scope(scope) as scope:\n",
    "            weights = self._variable_with_weight_decay('weights', [in_dim, out_dim], 0.04, 0.004)\n",
    "            biases = self._variable_on_cpu('biases', [out_dim], tf.constant_initializer(0.1))\n",
    "            if relu:\n",
    "                return tf.nn.relu(tf.matmul(inp, weights) + biases, name=scope.name)\n",
    "            else:\n",
    "                return tf.matmul(inp, weights) + biases\n",
    "\n",
    "    def inference(self, images):\n",
    "        \"\"\" build the model\n",
    "            -----\n",
    "            Args:\n",
    "                images with shape [batch_size,24,24,3]\n",
    "            Return:\n",
    "                logits with shape [batch_size,10]\n",
    "        \"\"\"\n",
    "        conv_1 = self._conv_block(images, 'conv_1', 5, 5, 3, 64)\n",
    "        # pool_1\n",
    "        pool_1 = tf.nn.max_pool(conv_1,ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool_1')\n",
    "        # norm_1 (local_response_normalization)\n",
    "        norm_1 = tf.nn.lrn(pool_1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm_1')\n",
    "\n",
    "        # conv2\n",
    "        conv_2 = self._conv_block(norm_1, 'conv_2', 5, 5, 64, 64)\n",
    "        # norm2\n",
    "        norm_2 = tf.nn.lrn(conv_2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm_2')\n",
    "        # pool2\n",
    "        pool_2 = tf.nn.max_pool(norm_2,ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool_2')\n",
    "\n",
    "        # Flatten feature maps before fully connected layers\n",
    "        flat_features = tf.reshape(pool_2, [self.batch_size, -1])\n",
    "        dim = flat_features.get_shape()[1].value\n",
    "        # FC_1 (fully-connected layer)\n",
    "        fc_1 = self._fully_connected_layer(flat_features, 'fc1', dim, 384)\n",
    "\n",
    "        # FC_2\n",
    "        fc_2 = self._fully_connected_layer(fc_1, 'fc2', 384, 192)\n",
    "\n",
    "        logits = self._fully_connected_layer(fc_2, 'softmax_linear', 192, self.num_classes, relu = False)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, logits, labels):\n",
    "        '''calculate the loss'''\n",
    "        labels = tf.cast(labels, tf.int64)\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "        tf.add_to_collection('losses', cross_entropy_mean)\n",
    "        # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "        # decay terms (L2 loss).\n",
    "        return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "    def train(self, total_loss, global_step):\n",
    "        '''Return training operation of one step'''\n",
    "        num_batches_per_epoch = self.num_training_example / self.batch_size\n",
    "        decay_steps = int(num_batches_per_epoch * self.num_epoch_per_decay)\n",
    "        # Decay the learning rate exponentially based on the number of steps.\n",
    "        lr = tf.train.exponential_decay(\n",
    "            self.init_lr, global_step, decay_steps, decay_rate=0.1, staircase=True)\n",
    "        opt = tf.train.GradientDescentOptimizer(lr)\n",
    "        grads = opt.compute_gradients(total_loss)\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "        # Track the moving averages of all trainable variables.\n",
    "        # This step just records the moving average weights but not uses them\n",
    "        ema = tf.train.ExponentialMovingAverage(self.moving_average_decay,\n",
    "                                                global_step)\n",
    "        self.ema = ema\n",
    "        variables_averages_op = ema.apply(tf.trainable_variables())\n",
    "        with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "            train_op = tf.no_op(name='train')\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, data_train , num_epoch):\n",
    "    saver = tf.train.Saver()\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator_train.initializer)\n",
    "        \n",
    "        ckpt = tf.train.get_checkpoint_state(model.ckpt_dir)\n",
    "        if (ckpt and ckpt.model_checkpoint_path):\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            # assume the name of checkpoint is like '.../model.ckpt-1000'\n",
    "            gs = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "            sess.run(tf.assign(model.global_step, gs))\n",
    "        else:\n",
    "          # no checkpoint found\n",
    "            print('no ckpt, init global variable...')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        model.loss_each_epoch = []\n",
    "\n",
    "        num_batch_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN//model.batch_size\n",
    "        #start training\n",
    "        for i in range(num_epoch):\n",
    "            _loss = []\n",
    "            print('epoch:',i)\n",
    "            for _ in range(num_batch_per_epoch):\n",
    "                print('.',end='')\n",
    "                images, labels = sess.run(data_train)\n",
    "                l, _ = sess.run([model.total_loss, model.train_op], feed_dict = {model.images:images, model.labels:labels})\n",
    "                _loss.append(l)\n",
    "            loss_this_epoch = np.sum(_loss)\n",
    "            gs = model.global_step.eval()\n",
    "            print('loss of epoch %d: %f' % (gs / num_batch_per_epoch, loss_this_epoch))\n",
    "            model.loss_each_epoch.append(loss_this_epoch)\n",
    "            saver.save(sess, model.ckpt_dir + 'model.ckpt', global_step=gs)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    print('Done training %d epochs' %num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_testing(model, data_test):\n",
    "    variables_to_restore = model.ema.variables_to_restore()\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "    with tf.Session() as sess:\n",
    "        # Restore variables from disk.\n",
    "        ckpt = tf.train.get_checkpoint_state(model.ckpt_dir)\n",
    "\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "            num_iter = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL // model.batch_size\n",
    "            total_sample_count = num_iter * model.batch_size\n",
    "            true_count = 0\n",
    "            for _ in range(num_iter):\n",
    "                images, labels = sess.run(data_test) \n",
    "\n",
    "                predictions = sess.run(model.top_k_op, feed_dict = {model.images:images, model.labels:labels})\n",
    "                true_count += np.sum(predictions)\n",
    "            print('Accurarcy: %d/%d = %f' % (true_count, total_sample_count,\n",
    "                                             true_count / total_sample_count))\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "        else:\n",
    "            print('train first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hps_cifar = tf.contrib.training.HParams(\n",
    "  image_size = IMAGE_SIZE_CROPPED,\n",
    "  batch_size = BATCH_SIZE,\n",
    "  num_classes = NUM_CLASSES,\n",
    "  num_training_example = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN,\n",
    "  num_epoch_per_decay = 350.0,\n",
    "  init_lr = 0.1,\n",
    "  moving_average_decay = 0.9999,\n",
    "  ckpt_dir = './model/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def cifar10_record_distort_parser(image,label):\n",
    "    ''' Parse the record into label, cropped and distorted image\n",
    "    -----\n",
    "    Args:\n",
    "        record: \n",
    "            a record containing label and image.\n",
    "    Returns:\n",
    "        label: \n",
    "            the label in the record.\n",
    "        image: \n",
    "            the cropped and distorted image in the record.\n",
    "    '''\n",
    "    \n",
    "    # TODO1\n",
    "    height = IMAGE_SIZE_CROPPED\n",
    "    width = IMAGE_SIZE_CROPPED\n",
    "    float_image = tf.cast(image, tf.float32)\n",
    "    distorted_image = tf.random_crop(float_image, [height, width, 3])\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    # standardization: subtract off the mean and divide by the variance of the pixels\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "    # Set the shapes of tensors.\n",
    "    distorted_image.set_shape([height, width, 3])\n",
    "    label.set_shape([1])\n",
    "    \n",
    "    # ensure a level of mixing of elements.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(\n",
    "      NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue)\n",
    "    # (8) example queue\n",
    "    # Filling queue with min_queue_examples CIFAR images before starting to train\n",
    "    image_batch, label_batch = tf.train.shuffle_batch(\n",
    "        [distorted_image, label],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_threads=16,\n",
    "        capacity=min_queue_examples + 3*BATCH_SIZE,\n",
    "        min_after_dequeue=min_queue_examples)\n",
    "    return image_batch, tf.reshape(label_batch, [BATCH_SIZE])\n",
    "\n",
    "\n",
    "\n",
    "def cifar10_record_crop_parser(image,label):\n",
    "    ''' Parse the record into label, cropped image\n",
    "    -----\n",
    "    Args:\n",
    "        record: \n",
    "            a record containing label and image.\n",
    "    Returns:\n",
    "        label: \n",
    "            the label in the record.\n",
    "        image: \n",
    "            the cropped image in the record.\n",
    "    '''\n",
    "    # create a queue that produces filenames to read\n",
    "    \n",
    "    # image preprocessing for training\n",
    "    height = IMAGE_SIZE_CROPPED\n",
    "    width = IMAGE_SIZE_CROPPED\n",
    "    float_image = tf.cast(image, tf.float32)\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(\n",
    "      float_image, height, width)\n",
    "    image_eval = tf.image.per_image_standardization(resized_image)\n",
    "    image_eval.set_shape([height, width, 3])\n",
    "    label.set_shape([1])\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(\n",
    "      NUM_EXAMPLES_PER_EPOCH_FOR_EVAL * min_fraction_of_examples_in_queue)\n",
    "    image_batch, label_batch = tf.train.batch(\n",
    "        [image_eval, label],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_threads=16,\n",
    "        capacity=min_queue_examples + 3*BATCH_SIZE)\n",
    "    return image_batch, tf.reshape(label_batch, [BATCH_SIZE])\n",
    "\n",
    "\n",
    "\n",
    "def cifar10_iterator(filenames, batch_size, cifar10_record_parser):\n",
    "    ''' Create a dataset and return a tf.contrib.data.Iterator \n",
    "    which provides a way to extract elements from this dataset.\n",
    "    -----\n",
    "    Args:\n",
    "        filenames: \n",
    "            a tensor of filenames.\n",
    "        batch_size: \n",
    "            batch size.\n",
    "    Returns:\n",
    "        iterator: \n",
    "            an Iterator providing a way to extract elements from the created dataset.\n",
    "        output_types: \n",
    "            the output types of the created dataset.\n",
    "        output_shapes: \n",
    "            the output shapes of the created dataset.\n",
    "    '''\n",
    "    \n",
    "    # TODO3\n",
    "    # tips: use dataset.map with cifar10_record_parser(record)\n",
    "    #       output_types = dataset.output_types\n",
    "    #       output_shapes = dataset.output_shapes\n",
    "    \n",
    "    file_queue = tf.train.string_input_producer(filenames)\n",
    "    cifar10_record = read_cifar10(file_queue)\n",
    "#     print(cifar10_record.image)\n",
    "    dataset = tf.data.Dataset.from_tensors((cifar10_record.image,cifar10_record.label))\n",
    "#     print(dataset)\n",
    "    dataset = dataset.map(cifar10_record_parser)\n",
    "#     print(dataset)\n",
    "    \n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     print(dataset)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    output_types = dataset.output_types\n",
    "    output_shapes = dataset.output_shapes\n",
    "    return iterator,output_types,output_shapes\n",
    "iterator_train, types, shapes = cifar10_iterator(filenames_train, BATCH_SIZE, cifar10_record_distort_parser)\n",
    "# iterator_test, _, _ = cifar10_iterator(filenames_test, BATCH_SIZE, cifar10_record_crop_parser)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#define training/testing data files\n",
    "training_files = [os.path.join(DATA_DIRECTORY, 'data_batch_%d.bin' % i) for i in range(1, 6)]\n",
    "testing_files = [os.path.join(DATA_DIRECTORY, 'test_batch.bin')]\n",
    "filenames_train = tf.constant(training_files)\n",
    "filenames_test = tf.constant(testing_files)\n",
    "# Training data iterator\n",
    "iterator_train, types, shapes = cifar10_iterator(filenames_train, BATCH_SIZE, cifar10_record_distort_parser)\n",
    "train_pairs= iterator_train.get_next()\n",
    "\n",
    "# # # Testing data iterator\n",
    "iterator_test, _, _ = cifar10_iterator(filenames_test, BATCH_SIZE, cifar10_record_crop_parser)\n",
    "\n",
    "\n",
    "# use to handle training and testing\n",
    "# handle = tf.placeholder(tf.string, shape=[])\n",
    "# iterator = tf.data.Iterator.from_string_handle(handle, types, shapes)\n",
    "# labels_images_pairs = iterator.get_next()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'shuffle_batch:0' shape=(128, 24, 24, 3) dtype=float32>, <tf.Tensor 'Reshape_1:0' shape=(128,) dtype=int32>)\n",
      "(<tf.Tensor 'IteratorGetNext:0' shape=(128, 24, 24, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(128,) dtype=int32>)\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-3900\n",
      "epoch: 0\n",
      ".INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[{{node shuffle_batch/random_shuffle_queue_enqueue}} = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, per_image_standardization, Cast)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8a253763bc18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_images_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-e6130c567854>\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m(model, data_train, num_epoch)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0m_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mloss_this_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# CNN model\n",
    "model = CNN_Model(model_hps_cifar)\n",
    "# Here we use CPU to handle the input because we want GPU to only focus on training.\n",
    "with tf.device('/cpu:0'):\n",
    "    data_train = distort_input(training_files, BATCH_SIZE)\n",
    "print(data_train)\n",
    "print(labels_images_pairs)\n",
    "run_training(model, data_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(model, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ckpt, init global variable...\n",
      "epoch: 0\n",
      ".INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[{{node input_producer_1/input_producer_1_EnqueueMany}} = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer_1, Const_1, ^input_producer_1/Assert/Assert)]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[128,24,24,3], [128]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-d6bcb457897e>\", line 10, in <module>\n    train_pairs= iterator_train.get_next()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 420, in get_next\n    name=name)), self._output_types,\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2068, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[128,24,24,3], [128]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[128,24,24,3], [128]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[0;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[128,24,24,3], [128]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-d6bcb457897e>\", line 10, in <module>\n    train_pairs= iterator_train.get_next()\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 420, in get_next\n    name=name)), self._output_types,\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2068, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\a1989\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[128,24,24,3], [128]], output_types=[DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO4:\n",
    "# 1. train the CNN model 10 epochs\n",
    "# 2. show the loss per epoch\n",
    "# 3. get the accuracy of this 10-epoch model\n",
    "# 4. measure the time using '%%time' instruction\n",
    "# tips:\n",
    "# use placeholder handle to determine if training or testing. \n",
    "# tf.reset_default_graph()\n",
    "# CNN model\n",
    "\n",
    "# Here we use CPU to handle the input because we want GPU to only focus on training.\n",
    "model = CNN_Model(model_hps_cifar)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(labels_images_pairs,feed_dict = {handle:iterator_train})\n",
    "        \n",
    "\n",
    "#     sess.run(iterator_train.initializer) # this stuck\n",
    "\n",
    "#     images, labels = sess.run(labels_images_pairs)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "num_epoch = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(model.ckpt_dir)\n",
    "    if (ckpt and ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # assume the name of checkpoint is like '.../model.ckpt-1000'\n",
    "        gs = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        sess.run(tf.assign(model.global_step, gs))\n",
    "    else:\n",
    "      # no checkpoint found\n",
    "        print('no ckpt, init global variable...')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    model.loss_each_epoch = []\n",
    "\n",
    "    num_batch_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN//model.batch_size\n",
    "    sess.run(iterator_train.initializer)\n",
    "    \n",
    "    #start training\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        _loss = []\n",
    "        print('epoch:',i)\n",
    "        for _ in range(num_batch_per_epoch):\n",
    "            print('.',end='')\n",
    "            sess.run(train_pairs)\n",
    "            \n",
    "            l, _ = sess.run([model.total_loss, model.train_op], feed_dict = {model.images:images, model.labels:labels})\n",
    "            _loss.append(l)\n",
    "        loss_this_epoch = np.sum(_loss)\n",
    "        gs = model.global_step.eval()\n",
    "        print('loss of epoch %d: %f' % (gs / num_batch_per_epoch, loss_this_epoch))\n",
    "        model.loss_each_epoch.append(loss_this_epoch)\n",
    "        saver.save(sess, model.ckpt_dir + 'model.ckpt', global_step=gs)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "print('Done training %d epochs' %num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "2018-11-02 23:16:47.751789: Start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                             | 0/390 [00:00<?, ?it/s]\n",
      "  0%|                                     | 1/390 [00:01<07:26,  1.15s/it]\n",
      "  1%|                                    | 2/390 [00:02<07:01,  1.09s/it]\n",
      "  1%|                                    | 3/390 [00:03<06:45,  1.05s/it]\n",
      "  1%|                                    | 4/390 [00:03<06:32,  1.02s/it]\n",
      "  1%|                                    | 5/390 [00:04<06:22,  1.01it/s]\n",
      "  2%|                                    | 6/390 [00:05<06:21,  1.01it/s]\n",
      "  2%|                                    | 7/390 [00:06<06:21,  1.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-0900f9043dd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_BATCH_PER_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mlbl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlbl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0m_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def cifar10_record_distort_parser(record):\n",
    "\n",
    "    record_bytes = LABEL_BYTES + IMAGE_BYTES\n",
    "    record = tf.decode_raw(record, tf.uint8)\n",
    "    label  = tf.cast(record[0], tf.int32)\n",
    "    \n",
    "    image = tf.reshape(record[1:record_bytes]\n",
    "                       , [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    \n",
    "    reshaped_image = tf.cast(tf.transpose(image, [1, 2, 0]), tf.float32)\n",
    "    distorted_image = tf.random_crop(reshaped_image\n",
    "                                     , [IMAGE_SIZE_CROPPED, IMAGE_SIZE_CROPPED, 3])\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "    \n",
    "    return label, distorted_image\n",
    "    \n",
    "\n",
    "\n",
    "def cifar10_record_crop_parser(record):\n",
    "\n",
    "    record_bytes = LABEL_BYTES + IMAGE_BYTES\n",
    "    record = tf.decode_raw(record, tf.uint8)\n",
    "    label  = tf.cast(record[0], tf.int32)\n",
    "    \n",
    "    image = tf.reshape(record[1:record_bytes]\n",
    "                       , [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    \n",
    "    reshaped_image = tf.cast(tf.transpose(image, [1, 2, 0]), tf.float32)\n",
    "    cropped_image = tf.random_crop(reshaped_image\n",
    "                                     , [IMAGE_SIZE_CROPPED, IMAGE_SIZE_CROPPED, 3])\n",
    "    cropped_image = tf.image.per_image_standardization(cropped_image)\n",
    "    \n",
    "    return label, cropped_image\n",
    "\n",
    "\n",
    "def cifar10_iterator(filenames, batch_size, cifar10_record_parser):\n",
    "\n",
    "    record_bytes = LABEL_BYTES + IMAGE_BYTES\n",
    "    dataset = tf.data.FixedLengthRecordDataset(filenames, record_bytes)\n",
    "    dataset = dataset.map(cifar10_record_parser)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(10)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    \n",
    "\n",
    "    return iterator, dataset.output_types, dataset.output_shapes\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "training_files = [os.path.join(DATA_DIRECTORY, 'data_batch_%d.bin' % i) for i in range(1, 6)]\n",
    "testing_files = [os.path.join(DATA_DIRECTORY, 'test_batch.bin')]\n",
    "\n",
    "filenames_train = tf.constant(training_files)\n",
    "filenames_test = tf.constant(testing_files)\n",
    "\n",
    "iterator_train, types, shapes = cifar10_iterator(filenames_train, BATCH_SIZE, cifar10_record_distort_parser)\n",
    "iterator_test, _, _ = cifar10_iterator(filenames_test, BATCH_SIZE, cifar10_record_crop_parser)\n",
    "\n",
    "next_batch = iterator_train.get_next()\n",
    "\n",
    "# use to handle training and testing\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, types, shapes)\n",
    "labels_images_pairs = iterator.get_next()\n",
    "\n",
    "\n",
    "# CNN model\n",
    "model = CNN_Model(model_hps_cifar)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    labels, images = labels_images_pairs\n",
    "    labels = tf.reshape(labels, [BATCH_SIZE])\n",
    "    images = tf.reshape(images, [BATCH_SIZE, IMAGE_SIZE_CROPPED, IMAGE_SIZE_CROPPED, IMAGE_DEPTH])\n",
    "\n",
    "# with tf.variable_scope('model'):\n",
    "#     logits = model.inference(images)\n",
    "\n",
    "\n",
    "# train\n",
    "global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "# total_loss = model.loss(logits, labels)\n",
    "# train_op = model.train(total_loss, global_step)\n",
    "# test\n",
    "# top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_EPOCH = 1\n",
    "NUM_BATCH_PER_EPOCH = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN // BATCH_SIZE\n",
    "ckpt_dir = './model/'\n",
    "\n",
    "# config = tf.ConfigProto(allow_soft_placement=True, gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "# train\n",
    "saver = tf.train.Saver()\n",
    "# with tf.Session(config=config) as sess:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    \n",
    "    if (ckpt and ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # assume the name of checkpoint is like '.../model.ckpt-1000'\n",
    "        gs = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        sess.run(tf.assign(global_step, gs))\n",
    "    else:\n",
    "        # no checkpoint found\n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    loss = []\n",
    "    training_handle = sess.run(iterator_train.string_handle())\n",
    "    \n",
    "    print(\"{}: Start training.\".format(datetime.now()))\n",
    "        \n",
    "    for i in range(NUM_EPOCH):\n",
    "        _loss = []\n",
    "        sess.run(iterator_train.initializer)\n",
    "\n",
    "        for j in  tqdm(range(NUM_BATCH_PER_EPOCH)):\n",
    "            tqdm.write(str(i))\n",
    "            lbl, img = sess.run(next_batch)            \n",
    "            l, _ = sess.run([model.total_loss, model.train_op], feed_dict={model.images: img, model.labels: lbl})\n",
    "\n",
    "            _loss.append(l)\n",
    "        loss_this_epoch = np.sum(_loss)\n",
    "        gs = global_step.eval()\n",
    "        print('{}: Loss of epoch {}: {}'.format(datetime.now(), gs / NUM_BATCH_PER_EPOCH, loss_this_epoch))\n",
    "        loss.append(loss_this_epoch)\n",
    "        saver.save(sess, ckpt_dir + 'model.ckpt', global_step=gs)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "  \n",
    "print(\"{}: Done training.\".format(datetime.now()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "next_test = iterator_test.get_next()\n",
    "variables_to_restore = model.ema.variables_to_restore()\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        num_iter = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL // BATCH_SIZE\n",
    "        total_sample_count = num_iter * BATCH_SIZE\n",
    "        true_count = 0\n",
    "        sess.run(iterator_test.initializer)\n",
    "        for _ in tqdm(range(num_iter)):\n",
    "            lbl, img = sess.run(next_test)\n",
    "            predictions = sess.run(top_k_op, feed_dict={images: img, labels: lbl})\n",
    "            true_count += np.sum(predictions)\n",
    "        print('{}: Accurarcy: {}/{} = {}'.format(datetime.now(), true_count, total_sample_count,\n",
    "                                     true_count / total_sample_count))\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    else:\n",
    "        print(\"{}: No model existed.\".format(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
