{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\Administrator\\Desktop\\DL\\Comp1\\big5_dict.txt ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.u4db63a6c4a8ce99b1489a4d22431124c.cache\n",
      "Loading model cost 1.596 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "def jieba_lines(lines):\n",
    "    cut_lines = []\n",
    "    for line in lines:\n",
    "        cut_line = jieba.lcut(line)\n",
    "        cut_lines.append(cut_line)\n",
    "    return cut_lines\n",
    "jieba.set_dictionary('big5_dict.txt')\n",
    "jieba.load_userdict('my_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut_programs = np.load('cut_Programs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_questions = []\n",
    "n = len(questions)\n",
    "\n",
    "for i in range(n):\n",
    "    cut_question = []\n",
    "    lines = questions.loc[i]['Question'].split('\\n')\n",
    "    cut_question.append(jieba_lines(lines))\n",
    "    \n",
    "    for j in range(6):\n",
    "        line = questions.loc[i]['Option%d' % (j)]\n",
    "        cut_question.append(jieba.lcut(line))\n",
    "    \n",
    "    cut_questions.append(cut_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 questions\n",
      "7\n",
      "[['輝哥', ' ', '全部', '都', '被', '你', '吃', '了', ' ', '你', '很', '過分'], ['就', '兩顆', ' ', '你還', '剩下', '這樣子', ' ', '那', '我', '吃', '什麼'], ['沒有', ' ', '因為', '你們', '一直', '在問', '問題', ' ', '我', '閒著', '無聊'], []]\n",
      "['然後', '煮', '一', '煮', '就', '變成', '紅色', '的', '嗎']\n",
      "['我', '就', '把', '它', '吃完', '了']\n",
      "['現在', '要', '把', '那個', '木頭', '給', '粉碎', '掉']\n",
      "['因為', '聽說', '以前', '是', '用燒', '的']\n",
      "['會', '造成', '空氣', '污染']\n",
      "['像', '他們', '現在', '這樣', '粉碎', '掉']\n"
     ]
    }
   ],
   "source": [
    "print(\"%d questions\" % len(cut_questions))\n",
    "print(len(cut_questions[0]))\n",
    "# 2 4\n",
    "n = 7\n",
    "# 1 question\n",
    "print(cut_questions[n][0])\n",
    "\n",
    "# 6 optional reponses\n",
    "for i in range(1, 7):\n",
    "    print(cut_questions[n][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('cut_Programs.npy', cut_programs)\n",
    "np.save('cut_Questions.npy', cut_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Word Dictionary & Out-of-Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 174424 words in word_dict\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "word_dict = dict()\n",
    "def add_word_dict(w):\n",
    "    if not w in word_dict:\n",
    "        word_dict[w] = 1\n",
    "    else:\n",
    "        word_dict[w] += 1\n",
    "for program in cut_programs:\n",
    "    for lines in program:\n",
    "        for line in lines:\n",
    "            for w in line:\n",
    "                add_word_dict(w)\n",
    "for question in cut_questions:\n",
    "    lines = question[0]\n",
    "    for line in lines:\n",
    "        for w in line:\n",
    "            add_word_dict(w)\n",
    "    \n",
    "    for i in range(1, 7):\n",
    "        line = question[i]\n",
    "        for w in line:\n",
    "            add_word_dict(w)\n",
    "\n",
    "word_dict = sorted(word_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"Total %d words in word_dict\" % len(word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('有', 119784), ('不', 118402), ('在', 117590), ('對', 111662), ('啊', 107267), ('...', 107010), ('要', 97042), ('好', 91516), ('這個', 90986), ('都', 90949)]\n",
      "\n",
      "Total 15000 words in voc_dict\n"
     ]
    }
   ],
   "source": [
    "VOC_START = 9\n",
    "VOC_SIZE = 15000\n",
    "voc_dict = word_dict[VOC_START:VOC_START+VOC_SIZE]\n",
    "print(voc_dict[:10])\n",
    "print()\n",
    "print(\"Total %d words in voc_dict\" % len(voc_dict))\n",
    "np.save('voc_dict.npy', voc_dict)\n",
    "voc_dict = np.load('voc_dict.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['而且', '很', '喜歡', '搞笑', '的', '阿輝']\n"
     ]
    }
   ],
   "source": [
    "print(cut_programs[0][0][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Generating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "NUM_TRAIN = 10000\n",
    "NUM_PROGRAM = 8\n",
    "TRAIN_VALID_RATE = 0.7\n",
    "def generate_training_data():\n",
    "    Xs, Ys = [], []\n",
    "    \n",
    "    for i in range(NUM_TRAIN):\n",
    "        pos_or_neg = random.randint(0, 1)\n",
    "        \n",
    "        if pos_or_neg==1:\n",
    "            program_id = random.randint(0, NUM_PROGRAM-1)\n",
    "            episode_id = random.randint(0, len(cut_programs[program_id])-1)\n",
    "            line_id = random.randint(0, len(cut_programs[program_id][episode_id])-2)\n",
    "            \n",
    "            Xs.append([cut_programs[program_id][episode_id][line_id], \n",
    "                       cut_programs[program_id][episode_id][line_id+1]])\n",
    "            Ys.append(1)\n",
    "            \n",
    "        else:\n",
    "            first_program_id = random.randint(0, NUM_PROGRAM-1)\n",
    "            first_episode_id = random.randint(0, len(cut_programs[first_program_id])-1)\n",
    "            first_line_id = random.randint(0, len(cut_programs[first_program_id][first_episode_id])-1)\n",
    "            \n",
    "            second_program_id = random.randint(0, NUM_PROGRAM-1)\n",
    "            second_episode_id = random.randint(0, len(cut_programs[second_program_id])-1)\n",
    "            second_line_id = random.randint(0, len(cut_programs[second_program_id][second_episode_id])-1)\n",
    "            \n",
    "            Xs.append([cut_programs[first_program_id][first_episode_id][first_line_id], \n",
    "                       cut_programs[second_program_id][second_episode_id][second_line_id]])\n",
    "            Ys.append(0)\n",
    "    \n",
    "    return Xs, Ys\n",
    "Xs, Ys = generate_training_data()\n",
    "\n",
    "x_train, y_train = Xs[:int(NUM_TRAIN*TRAIN_VALID_RATE)], Ys[:int(NUM_TRAIN*TRAIN_VALID_RATE)]\n",
    "x_valid, y_valid = Xs[int(NUM_TRAIN*TRAIN_VALID_RATE):], Ys[int(NUM_TRAIN*TRAIN_VALID_RATE):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p items: 2394065\n",
      "p+n items: 2394065\n"
     ]
    }
   ],
   "source": [
    "def greedy_gen():\n",
    "    Xs, Ys = [], []\n",
    "    all_pos = 0\n",
    "    all_neg = 0\n",
    "    for ep in cut_programs:\n",
    "        for lines in ep:\n",
    "            for line_id in range(len(lines)-1): \n",
    "                Xs.append([lines[line_id], \n",
    "                           lines[line_id+1]])\n",
    "                Ys.append(1)\n",
    "                all_pos+=1\n",
    "    print(\"p items:\",all_pos)\n",
    "####################\n",
    "    for i in range(all_pos):\n",
    "        first_program_id = random.randint(0, NUM_PROGRAM-1)\n",
    "        first_episode_id = random.randint(0, len(cut_programs[first_program_id])-1)\n",
    "        first_line_id = random.randint(0, len(cut_programs[first_program_id][first_episode_id])-1)\n",
    "\n",
    "        second_program_id = random.randint(0, NUM_PROGRAM-1)\n",
    "        second_episode_id = random.randint(0, len(cut_programs[second_program_id])-1)\n",
    "        second_line_id = random.randint(0, len(cut_programs[second_program_id][second_episode_id])-1)\n",
    "\n",
    "        Xs.append([cut_programs[first_program_id][first_episode_id][first_line_id], \n",
    "                   cut_programs[second_program_id][second_episode_id][second_line_id]])\n",
    "        Ys.append(0)\n",
    "        all_neg+=1\n",
    "    print(\"p+n items:\",all_pos+all_neg)\n",
    "    return Xs, Ys\n",
    "# Xs, Ys = greedy_gen()\n",
    "# x_train, y_train = Xs[:int(NUM_TRAIN*TRAIN_VALID_RATE)], Ys[:int(NUM_TRAIN*TRAIN_VALID_RATE)]\n",
    "# x_valid, y_valid = Xs[int(NUM_TRAIN*TRAIN_VALID_RATE):], Ys[int(NUM_TRAIN*TRAIN_VALID_RATE):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Xs.npy', Xs)\n",
    "np.save('Ys.npy', Ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['我', '覺得', '心是', '很', '重要', '的'], ['直接', '進入', '你', '腦部']]\n",
      "['還好', '天氣', '不錯']\n"
     ]
    }
   ],
   "source": [
    "print(Xs[1])\n",
    "print(cut_programs[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['還好 天氣 不錯 ', '昨天 晚上 ', '看到 很多 流星 ', '這次 收穫 真 豐富 ', '當然 豐富 啦 ', '說 嘛 ', '精心 製作 ', '被 一個 人 吃掉 ', '真的 嗎 ', '不要 忘記 要 做 秘密 檔案 ']\n"
     ]
    }
   ],
   "source": [
    "example_doc = []\n",
    "\n",
    "# lines in 1st episode in program 0 \n",
    "for line in cut_programs[0][0]:\n",
    "    example_line = ''\n",
    "    for w in line:\n",
    "        if w in voc_dict:\n",
    "            example_line += w+' '\n",
    "        \n",
    "    example_doc.append(example_line)\n",
    "\n",
    "print(example_doc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: BoW (Bag-Of-Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocabulary]\n",
      "\n",
      "還好 469\n",
      "天氣 168\n",
      "不錯 46\n",
      "昨天 268\n",
      "晚上 270\n",
      "看到 352\n",
      "很多 217\n",
      "流星 310\n",
      "這次 456\n",
      "收穫 259\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ngram_range=(min, max), default: 1-gram => (1, 1)\n",
    "count = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "count.fit(example_doc)\n",
    "BoW = count.vocabulary_\n",
    "print('[vocabulary]\\n')\n",
    "for key in list(BoW.keys())[:10]:\n",
    "    print('%s %d' % (key, BoW[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
