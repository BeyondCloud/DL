{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\" # choose which GPU you want to use\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import urllib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# load mnist data\n",
    "mnist = input_data.read_data_sets(\"data\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full connected layer 1 w\n",
      "[[-6.2220893  -0.53706723  2.9599993  -5.7578382   6.3434434  -6.9728923 ]\n",
      " [ 4.6419377  -0.22326803 -5.282519    7.6141953  -4.604753   -6.415772  ]]\n",
      "full connected layer 1 bias\n",
      "[-1.9162577  -0.90517175 -0.7304128   2.4763248   1.9582983   2.0814915 ]\n",
      "full connected layer 1 w\n",
      "[[ 4.6504145 ]\n",
      " [ 0.54976463]\n",
      " [ 3.1749053 ]\n",
      " [-3.4743433 ]\n",
      " [-1.9929037 ]\n",
      " [-3.0789042 ]]\n",
      "full connected layer 1 bias\n",
      "[2.1787846]\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# setting \n",
    "feature_dims = 2\n",
    "neurons = 5\n",
    "classes = 1\n",
    "learning_rate = 0.1\n",
    "def fully_connected_layer(x_inputs, out_dim, name='fc'):\n",
    "    \"\"\" Low level method\n",
    "        x_inputs: a batch examples [batch_size, feature_dims]\n",
    "        out_dim: neurons in this layer.\n",
    "    \"\"\" \n",
    "    in_dim = x_inputs.shape[-1] # feature_dims\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        weights = tf.get_variable(\"weights\", shape=[in_dim, out_dim])\n",
    "        bias = tf.get_variable(\"bias\", shape=[out_dim])\n",
    "        out = tf.matmul(x_inputs, weights) + bias\n",
    "        return out\n",
    "# xor task\n",
    "xor_data = np.array([[1, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 1],\n",
    "                    [0, 0]])\n",
    "xor_label = np.array([[1], [1], [0], [0]])\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    x_input = tf.placeholder(tf.float32, [None, 2])\n",
    "    y_label = tf.placeholder(tf.float32, [None, 1])\n",
    "    # start building your model and meet the requirements\n",
    "    # from here\n",
    "    \n",
    "    out = fully_connected_layer(x_input,6,'L1')\n",
    "    out = fully_connected_layer( tf.sigmoid(out),1, \"L2\")\n",
    "    out = tf.sigmoid(out)\n",
    "\n",
    "    loss = tf.reduce_mean((out-y_label)**2, name=\"Logist\")\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    training_op = optimizer.minimize(loss,name = \"training_op\")\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # start run the seesion and meet the requrements\n",
    "    # from here\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        sess.run([loss,training_op],feed_dict={x_input: xor_data,y_label: xor_label})\n",
    "        \n",
    "    x = sess.run(out,feed_dict={x_input: xor_data})\n",
    "    with tf.variable_scope(\"L1\", reuse=True):\n",
    "        print('full connected layer 1 w')\n",
    "        v = tf.get_variable(\"weights\")\n",
    "        print(sess.run(v))\n",
    "        \n",
    "        print('full connected layer 1 bias')\n",
    "        v = tf.get_variable(\"bias\")\n",
    "        print(sess.run(v))\n",
    "    with tf.variable_scope(\"L2\", reuse=True):\n",
    "        print('full connected layer 1 w')\n",
    "        v = tf.get_variable(\"weights\")\n",
    "        print(sess.run(v))\n",
    "        \n",
    "        print('full connected layer 1 bias')\n",
    "        v = tf.get_variable(\"bias\")\n",
    "        print(sess.run(v))\n",
    "        \n",
    "#         vs.\n",
    "#     var = [v for v in tf.trainable_variables()][0]\n",
    "    print('acc:',sum((xor_label==np.round(x))/4)[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Problem Definition] <br>\n",
    "Build a fully connected network to challenge this task.<br>\n",
    "Input: an image of shape=[784]<br>\n",
    "Output: a digit of this image, shape=[10]\n",
    "\n",
    "[Requirements]<br>\n",
    "Show the code of graph and session you build.<br>\n",
    "Use tf.data.Dataset and tf.data.Iterator to extract data.<br>\n",
    "Use low level API method to build the model (define the weights and bias from scratch like above).<br>\n",
    "The accuracy on mnist.test should be at least 95%.\n",
    "\n",
    "[Notes]<br>\n",
    "the hyperparameters are not constrainted (e.g. num_neurons_in_one_layer, how_many_layers, learning_rates, training_epochs, batch_size)<br>\n",
    "the optimizer are not constrainted.<br>\n",
    "mnist.train is all you can use to train the model. mnist.validation are just used to be validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cond/Merge:0\", shape=(?, 784), dtype=float32)\n",
      "Test accuracy: 0.953125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "###### Do not modify here ###### \n",
    "def fully_connected_layer(x_inputs, out_dim, name='fc'):\n",
    "    \"\"\" Low level method\n",
    "        x_inputs: a batch examples [batch_size, feature_dims]\n",
    "        out_dim: neurons in this layer.\n",
    "    \"\"\" \n",
    "    in_dim = x_inputs.shape[-1] # feature_dims\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        weights = tf.get_variable(\"weights\", shape=[in_dim, out_dim])\n",
    "        bias = tf.get_variable(\"bias\", shape=[out_dim])\n",
    "        out = tf.matmul(x_inputs, weights) + bias\n",
    "        return out\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "\n",
    "# mnist = input_data.read_data_sets(\"data\", one_hot=True)\n",
    "# mnist = input_data.read_data_sets(\"data\")\n",
    "if not mnist:\n",
    "    mnist = input_data.read_data_sets(\"data\")\n",
    "\n",
    "\n",
    "# training on MNIST but only on digits 0 to 4\n",
    "X_train1 = mnist.train.images\n",
    "y_train1 = mnist.train.labels\n",
    "\n",
    "X_test1 = mnist.test.images\n",
    "y_test1 = mnist.test.labels\n",
    "\n",
    "###### Do not modify here ###### \n",
    "\n",
    "#get next batch in order\n",
    "def next_batch(batch_size,iteration, data, labels):\n",
    "    start = batch_size*iteration\n",
    "    end = batch_size*(iteration+1)\n",
    "    return data[start:end], labels[start:end]\n",
    "\n",
    "#const parameters\n",
    "n_inputs = 784  # MNIST\n",
    "n_outputs = 10\n",
    "\n",
    "#adjustable parameters\n",
    "N_neurons = 128\n",
    "learning_rate = 0.01\n",
    "momentum = 0.25\n",
    "epochs = 2\n",
    "batch_size = 128  #for GPU optimize\n",
    "dropout = 0.5\n",
    "\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((mnist.train.images,mnist.train.labels)) \n",
    "    training_dataset = training_dataset.batch(batch_size)\n",
    "    train_iterator = training_dataset.make_one_shot_iterator()\n",
    "\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((mnist.test.images,mnist.test.labels))\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    test_iterator = test_dataset.make_one_shot_iterator()\n",
    "    is_test = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "    X,y = tf.cond(is_test, lambda:test_iterator.get_next(), lambda:train_iterator.get_next())\n",
    "    print(X)\n",
    "    # X = tf.manip.reshape(X,(-1,784))\n",
    "    # # X = tf.transpose(X)\n",
    "    y= tf.cast(y, tf.int64)\n",
    "    # y = tf.manip.reshape(y,(-1,))\n",
    "\n",
    "    # X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "    # y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "    # print(X) #(?,784)\n",
    "\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    W1 = tf.sigmoid(fully_connected_layer(X,N_neurons,name='L1')) \n",
    "    # print(W1) #(?,128)\n",
    "\n",
    "    W2 = tf.sigmoid(fully_connected_layer(W1,N_neurons,name='L2'))\n",
    "    # print(W2) #(?,128)\n",
    "\n",
    "    y_hat = fully_connected_layer(W2, n_outputs,name = 'L3')\n",
    "    # print(y_hat) #(?,10)\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_hat)\n",
    "    loss = tf.reduce_mean(cross_entropy, name=\"loss\")\n",
    "\n",
    "    #use AdamOptimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss,name = \"training_op\")\n",
    "\n",
    "\n",
    "    correct = tf.nn.in_top_k(y_hat,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32), name=\"accuracy\")\n",
    "\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for iteration in range(50):\n",
    "            sess.run(training_op,feed_dict={is_test:False} )            \n",
    "\n",
    "    acc_test = sess.run(accuracy,feed_dict={is_test:True} )\n",
    "        \n",
    "    print( \"Test accuracy:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
